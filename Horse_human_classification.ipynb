{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import random\n",
    "import os ,signal\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-03 16:07:15--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.167.240\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.167.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149574867 (143M) [application/zip]\n",
      "Saving to: ‘/tmp/horse-or-human.zip’\n",
      "\n",
      "/tmp/horse-or-human 100%[===================>] 142.65M  3.96MB/s    in 34s     \n",
      "\n",
      "2020-05-03 16:07:50 (4.23 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
    "    -O /tmp/horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
    "zip_ref.extractall('/tmp/horse-or-human')\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/horse-or-human/horses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fab8c9e373db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_human_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/horse-or-human/humans'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_horse_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_horse_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_horse_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_human_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_human_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/horse-or-human/horses'"
     ]
    }
   ],
   "source": [
    "train_horse_dir = os.path.join('tmp/horse-or-human/horses')\n",
    "train_human_dir = os.path.join('tmp/horse-or-human/humans')\n",
    "\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "pic_index = 0\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4,nrows*4)\n",
    "\n",
    "pic_index += 8\n",
    "\n",
    "next_horse_pix = [os.path.join(train_horse_dir,fname)\n",
    "                 for fname in train_horse_names[pic_index - 8:pic_index]]\n",
    "next_horse_pix = [os.path.join(train_human_dir,fname)\n",
    "                 for fname in train_human_names[pic_index - 8:pic_index]]\n",
    "\n",
    "\n",
    "for i , img_path in enumerate (next_horse_pix + next_human_pix):\n",
    "    sp = plt.subplot(nrows , ncols,i+1)\n",
    "    sp.axis('Off')\n",
    "    \n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(lr=0.001),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "'/tmp/horse-or-human',\n",
    "target_size = (300,300),\n",
    "batch_size = 128,\n",
    "class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch = 8,\n",
    "                   epochs = 15,\n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Convnet for each layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succesive_outputts = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input,outputs = successive_outputs)\n",
    "\n",
    "\n",
    "horse_img_files = [os.path.join(train_horse_dir,f) for f in train_horse_names]\n",
    "human_img_files = [os.apth.join(train_human_dir,f) for f in train_human_names]\n",
    "img_path = random.choice(horse_immg_files + human_img_files)\n",
    "\n",
    "\n",
    "img  = load_img(img_path, traget_size=(300,300))\n",
    "\n",
    "x = img_to_array(img)\n",
    "x= x.resape((1,) + x.shape)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "layer_names = [laye.name for layer in moddel.layers]\n",
    "\n",
    "for layer_name , feature_map in zip(layer_names , successive_feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "        n_features = feature_map.shape[-1]\n",
    "        size = feature_map.shape[-1]\n",
    "        size = feature_map.shape[1]\n",
    "        display_grid = np.zeros((size,size,*n_features))\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            \n",
    "            x = feature_amap[0,:,:,i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x,0,255).astype('uint8')\n",
    "            \n",
    "            display_grid[:,i*size :(i+1) * size ] = x\n",
    "        \n",
    "        \n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize = (scale *n_features,scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto' , cmap = 'viridis')\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
